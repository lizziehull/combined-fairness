{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbKLxECcOiL9"
   },
   "source": [
    "# Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jv5Oui0-eWt3"
   },
   "outputs": [],
   "source": [
    "NUM = 5500\n",
    "TRAIN = 3500\n",
    "VAL = 1000\n",
    "SPLIT = 3\n",
    "DIM = 64\n",
    "BOUNDARY = 2.85\n",
    "NUM_FEATURES = 64\n",
    "NOISE = 128\n",
    "GAN_BATCH_SIZE = 4\n",
    "CLASSIFIER_BATCH_SIZE = 8\n",
    "D_LEARNING_RATE = 0.0001\n",
    "G_LEARNING_RATE = 0.0001\n",
    "CLASSIFIER_LEARNING_RATE = 0.0005\n",
    "TEXT1 = 'Female'\n",
    "TEXT0 = 'Male'\n",
    "DATASET = 'SCUT'\n",
    "URL = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfaUWCURWXSm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "if URL != '':\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8OC2yzQUS_9",
    "outputId": "8b5075c7-70a8-4fdb-e6e1-3f1d391579cf"
   },
   "outputs": [],
   "source": [
    "if URL != '':\n",
    "    from google.colab import drive\n",
    "    drive.mount('./mount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSq8Bo3Bvsh1"
   },
   "source": [
    "# Helper Functions: Tracking and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJ-X2nX-_XBG"
   },
   "outputs": [],
   "source": [
    "class Tracker():\n",
    "  def __init__(self):\n",
    "\n",
    "    self.j = random.randint(1, 1000)\n",
    "    self.epoch = 1\n",
    "\n",
    "    self.count = 0\n",
    "    self.real_count = 0\n",
    "    self.fake_count = 0\n",
    "    self.acc_fake = 0\n",
    "    self.acc_real = 0\n",
    "    self.acc_list = []\n",
    "    self.acc_list_fake = []\n",
    "    self.acc_list_real = []\n",
    "    self.d_loss_list = []\n",
    "    self.g_loss_list = []\n",
    "\n",
    "  def add_d_loss(self, loss):\n",
    "    self.d_loss_list.append(loss)\n",
    "    \n",
    "  def add_g_loss(self, loss):\n",
    "    self.g_loss_list.append(loss)\n",
    "\n",
    "  def add_epoch(self):\n",
    "    self.epoch += 1\n",
    "    \n",
    "  def change_j(self, num):\n",
    "    self.j = num\n",
    "        \n",
    "  def set_epoch(self, num):\n",
    "    self.epoch = num\n",
    "\n",
    "  def track(self, source, outputs_source):\n",
    "\n",
    "    # increase counters\n",
    "    self.count += GAN_BATCH_SIZE \n",
    "    if source == 'Real':\n",
    "      self.real_count += GAN_BATCH_SIZE\n",
    "    elif source == 'Fake':\n",
    "      self.fake_count += GAN_BATCH_SIZE\n",
    "\n",
    "    # calculate accuracies\n",
    "    for i in range(GAN_BATCH_SIZE):\n",
    "      if source == 'Real' and outputs_source[i].item() >= 0.5:\n",
    "        self.acc_real += 1\n",
    "      elif source == 'Fake' and outputs_source[i].item() < 0.5:\n",
    "        self.acc_fake += 1\n",
    "\n",
    "    # log accuracies\n",
    "    self.acc_list.append((self.acc_real + self.acc_fake) / self.count)\n",
    "    if source == 'Real':\n",
    "      self.acc_list_real.append(self.acc_real / self.real_count)\n",
    "    elif source == 'Fake':\n",
    "      self.acc_list_fake.append(self.acc_fake / self.fake_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2iHPIOTKFHo"
   },
   "outputs": [],
   "source": [
    "class C_Tracker():\n",
    "  def __init__(self):\n",
    "    self.j = random.randint(1, 1000)\n",
    "    self.train_acc = []\n",
    "    self.val_acc = []\n",
    "    self.loss_list = []\n",
    "    \n",
    "  def add_train_acc(self, acc):\n",
    "    self.train_acc.append(acc)\n",
    "    \n",
    "  def add_val_acc(self, acc):\n",
    "    self.val_acc.append(acc)\n",
    "\n",
    "  def add_loss(self, loss):\n",
    "    self.loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcctV6nzQ7zq"
   },
   "outputs": [],
   "source": [
    "def check_skew(dataset):\n",
    "\n",
    "  pos_count = 0\n",
    "  s1_count = 0\n",
    "  s1_pos = 0\n",
    "    \n",
    "  total = len(dataset)\n",
    "  dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "  for batch in dataloader:\n",
    "    _, y, s = batch\n",
    "\n",
    "    if y.item() == 1.0:\n",
    "      pos_count += 1\n",
    "      if s.item() == 1.0:\n",
    "        s1_pos += 1\n",
    "                \n",
    "    if s.item() == 1.0:\n",
    "      s1_count += 1\n",
    "    \n",
    "  neg_count = total - pos_count\n",
    "  s0_count = total - s1_count\n",
    "  s0_pos = pos_count - s1_pos\n",
    "  s1_neg = s1_count - s1_pos\n",
    "  s0_neg = s0_count - s0_pos\n",
    "\n",
    "  print(f'Total is {total}.')\n",
    "  print(f'Number of positives is {pos_count} or {round(pos_count / total * 100, 3)}%.')\n",
    "  print(f'Number of negatives is {neg_count} or {round(neg_count / total * 100, 3)}%.')\n",
    "  print(f'Number of {TEXT1} faces is {s1_count} or {round(s1_count / total * 100, 3)}%.')\n",
    "  print(f'Number of {TEXT0} faces is {s0_count} or {round(s0_count / total * 100, 3)}%.')\n",
    "  print(f'Number of {TEXT1} positives is {s1_pos}: {round(s1_pos / s1_count * 100, 3)}% of {TEXT1} faces or {round(s1_pos / total * 100, 3)}% of total.')\n",
    "  print(f'Number of {TEXT0} positives is {s0_pos}: {round(s0_pos / s0_count * 100, 3)}% of {TEXT0} faces or {round(s1_neg / total * 100, 3)}% of total.')\n",
    "  print(f'Number of {TEXT1} negatives is {s1_neg}: {round(s1_neg / s1_count * 100, 3)}% of {TEXT1} faces or {round(s0_pos / total * 100, 3)}% of total.')\n",
    "  print(f'Number of {TEXT0} negatives is {s0_neg}: {round(s0_neg / s0_count * 100, 3)}% of {TEXT0} faces or {round(s0_neg / total * 100, 3)}% of total.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWDmxzn0_Ac3"
   },
   "outputs": [],
   "source": [
    "def plot(l, title):\n",
    "  df = pd.DataFrame(l, columns=[title])\n",
    "  df.plot(ylim = (0), figsize = (10, 5), alpha = 0.1, marker = '.', grid = True, yticks = (0, 0.25, 0.5, 0.75, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8kvprodrSIh"
   },
   "outputs": [],
   "source": [
    "def plot_gan(T):\n",
    "  plot(T.d_loss_list, 'Discriminator Loss')\n",
    "  plot(T.g_loss_list, 'Generator Loss')\n",
    "  plot(T.acc_list, 'Discriminator Accuracy')\n",
    "  plot(T.acc_list_real, 'Discriminator Accuracy - Real')\n",
    "  plot(T.acc_list_fake, 'Discriminator Accuracy - Fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVC2q5SrBS2K"
   },
   "outputs": [],
   "source": [
    "def plot_classifier(CT):\n",
    "  plot(CT.loss_list, 'Classifier Loss')\n",
    "  plot(CT.train_acc, 'Train Set Accuracy')\n",
    "  plot(CT.val_acc, 'Validation Set Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkvoKUBqjIER"
   },
   "outputs": [],
   "source": [
    "def generate_images(G):\n",
    "  f, axarr = plt.subplots(4, 4, figsize = (10, 5))\n",
    "  for i in range(4):\n",
    "    t = G.forward(torch.randn(GAN_BATCH_SIZE, NOISE, 1, 1).to(device))\n",
    "    t = (t * 0.5) + 0.5 # undo normalisation\n",
    "    for j in range(4):\n",
    "      img = transforms.ToPILImage()(t[j])\n",
    "      axarr[i, j].imshow(img)\n",
    "      axarr[i, j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtsbDaapfat3"
   },
   "source": [
    "# Helper Functions: Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnTQVXxXQ7zn"
   },
   "outputs": [],
   "source": [
    "# based on https://www.youtube.com/watch?v=ZoZHd0Zm3RY\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "  def __init__(self, csv, root, size):\n",
    "    self.f = pd.read_csv(csv, header=None)\n",
    "    self.root = root\n",
    "    self.size = size\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.f)\n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    # generate correct file path\n",
    "    img_path = os.path.join(self.root, self.f.iloc[index, 0])\n",
    "        \n",
    "    # open image\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # resize image\n",
    "    img = img.resize((self.size, self.size), 0)\n",
    "        \n",
    "    # ToTensor divides all values by 255\n",
    "    # normalizing transforms all values from [0, 1] to [-1, 1] for tanh\n",
    "    edit = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize([0.5], [0.5])])\n",
    "        \n",
    "    X = edit(img)\n",
    "\n",
    "    y = torch.zeros(1)\n",
    "    if self.f.iloc[index, 1] >= BOUNDARY:\n",
    "      y = torch.ones(1)\n",
    "\n",
    "    s = torch.zeros(1)\n",
    "    if self.f.iloc[index, 0][1] == 'F':\n",
    "      s = torch.ones(1)\n",
    "            \n",
    "    return X, y, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3erfsv_sPaxt"
   },
   "outputs": [],
   "source": [
    "class RealDataset(Dataset):\n",
    "  def __init__(self, X, y, s):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.s = s\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    return self.X[index], self.y[index], self.s[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairDataset(Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTDXraLOwlRL"
   },
   "outputs": [],
   "source": [
    "def generate_dataset(G, D, text, index):\n",
    "    \n",
    "  i = 0\n",
    "  \n",
    "  G.eval()\n",
    "  D.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    while i < TRAIN:\n",
    "\n",
    "      X = G.forward(torch.randn(GAN_BATCH_SIZE, NOISE, 1, 1).to(device))\n",
    "\n",
    "      _, y = D.forward(X.to(device).detach())\n",
    "\n",
    "      for j in range(GAN_BATCH_SIZE):\n",
    "\n",
    "        if i < TRAIN:\n",
    "\n",
    "          img = X[j].unsqueeze(0)\n",
    "          i += 1\n",
    "          if y[j].item() >= 0.5:\n",
    "            z = 1\n",
    "          else:\n",
    "            z = 0\n",
    "          save_data(img, z, -1, text, index, i)\n",
    "            \n",
    "  G.train()\n",
    "  D.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XO0yTK2IdjTA"
   },
   "outputs": [],
   "source": [
    "def save_data(X, y, s, text, index, i):\n",
    "  root = f'{URL}{DATASET}/{text}/{index}/'\n",
    "\n",
    "  # write X tensor to file\n",
    "  np.save(root + 'X' + str(i), X.detach().cpu().numpy())\n",
    "  # write y float to file\n",
    "\n",
    "  f = open(root + 'y.txt', 'a')\n",
    "  f.write(str(int(y)))\n",
    "  f.close()\n",
    "  \n",
    "  if s != -1:\n",
    "    # write s float to file\n",
    "    f = open(root + 's.txt', 'a')\n",
    "    f.write(str(int(s)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M32rGfloturp"
   },
   "outputs": [],
   "source": [
    "def save_split(loader, text, index, fair):\n",
    "  count = 0\n",
    "  if fair == True:\n",
    "    for batch in loader:\n",
    "      X, y = batch\n",
    "      for i in range(len(X)):\n",
    "        count += 1\n",
    "        save_data(X[i], y[i], -1, text, index, count)\n",
    "  else:\n",
    "    for batch in loader:\n",
    "      X, y, s = batch\n",
    "      for i in range(len(X)):\n",
    "        count += 1\n",
    "        save_data(X[i], y[i], -1, text, index, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1wBlaJSbxTQ"
   },
   "outputs": [],
   "source": [
    "def save_splits(text, train_loader, validation_loader, test_loader):\n",
    "  save_split(train_loader, text, 'Train')\n",
    "  save_split(validation_loader, text, 'Validation')\n",
    "  if test_loader != -1:\n",
    "    save_split(test_loader, text, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y533GPJtcIAl"
   },
   "outputs": [],
   "source": [
    "def read_split(text, batch_size, kind, load, fair):\n",
    "\n",
    "  if kind == 'Train':\n",
    "    n = int((7 * NUM) / 11)\n",
    "    shuff = True\n",
    "  elif kind == 'Validation' or kind == 'Test':\n",
    "    n = int((2 * NUM) / 11)\n",
    "    shuff = False\n",
    "    \n",
    "  if fair == True:\n",
    "    X, y = read_tensors(text, kind, n, True)\n",
    "    my_data = FairDataset(X, y)\n",
    "  else:\n",
    "    X, y, s = read_tensors(text, kind, n, False)\n",
    "    my_data = RealDataset(X, y, s)\n",
    "\n",
    "  if load == True:\n",
    "    my_loader = DataLoader(my_data, batch_size, shuff)\n",
    "    return my_loader\n",
    "  else:\n",
    "    return my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJBrkYWADwhG"
   },
   "outputs": [],
   "source": [
    "# read X tensor from file\n",
    "def tensor_helper(doc, n):\n",
    "  X = torch.zeros(n, 3, DIM, DIM).to(device)\n",
    "  for i in range(n):\n",
    "    X[i] = torch.from_numpy(np.load(doc + f'X{i + 1}.npy'))\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wdboli_dDwhG"
   },
   "outputs": [],
   "source": [
    "# read y and s tensors from file\n",
    "def float_helper(doc, n):\n",
    "  l = []\n",
    "  f = open(doc)\n",
    "  for i in range(n):\n",
    "    c = f.read(1)\n",
    "    l.append(int(c))\n",
    "  f.close()\n",
    "  return torch.FloatTensor(l).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvCq72oxDwhG"
   },
   "outputs": [],
   "source": [
    "# read in X, y and s tensors using filepath\n",
    "def read_tensors(text, index, n, fair):\n",
    "\n",
    "  f1 = f'{URL}{DATASET}/{text}/{index}/'\n",
    "  f2 = f'{URL}{DATASET}/{text}/{index}/y.txt'\n",
    "\n",
    "  X = tensor_helper(f1, n)\n",
    "  y = float_helper(f2, n)\n",
    "    \n",
    "  if fair == False:\n",
    "    f3 = f'{URL}{DATASET}/{text}/{index}/s.txt'\n",
    "    s = float_helper(f3, n)\n",
    "    return X, y, s\n",
    "\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laOHlwr-tR43"
   },
   "outputs": [],
   "source": [
    "def load_real_data(dataset, batch_size, a, b, c):\n",
    "  n = len(dataset)\n",
    "  train_data, validation_data, test_data = torch.utils.data.random_split(dataset, [int(n * a), int(n * b), int(n * c)])\n",
    "\n",
    "  train_loader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "  validation_loader = DataLoader(validation_data, batch_size, shuffle=False)\n",
    "  test_loader = DataLoader(test_data, batch_size, shuffle=False)\n",
    "\n",
    "  return train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p99ml1s3KJ-f"
   },
   "source": [
    "# Helper Functions: GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nS3Alg7aTF3n"
   },
   "outputs": [],
   "source": [
    "def threshold(t, index):\n",
    "  if t[index].item() >= 0.5:\n",
    "    return 1.0\n",
    "  else:\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrNTBptvQ7z0"
   },
   "outputs": [],
   "source": [
    "def initialise_weights(model):\n",
    "\n",
    "  for m in model.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "      nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "      nn.init.normal_(m.weight.data, 1.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko5zFhpOhAqw"
   },
   "outputs": [],
   "source": [
    "def random_classes():\n",
    "  return torch.randint(2, (GAN_BATCH_SIZE,)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQM3sV0FjlLr"
   },
   "outputs": [],
   "source": [
    "def save_gan(G, D, text, j, epoch): \n",
    "    \n",
    "  f = f'{URL}{DATASET}/{text}/Params/Gen_{text}{j}_{epoch}.pt'\n",
    "\n",
    "  torch.save(G.state_dict(), f)\n",
    "\n",
    "  f = f'{URL}{DATASET}/{text}/Params/Disc_{text}{j}_{epoch}.pt'\n",
    "\n",
    "  torch.save(D.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIUZDlFOv-yq"
   },
   "outputs": [],
   "source": [
    "def load_gan(text, j, epoch):\n",
    "\n",
    "  G = Generator(NOISE, NUM_FEATURES)\n",
    "  D = Discriminator(NUM_FEATURES)\n",
    "  T = Tracker()\n",
    "  D.to(device)\n",
    "  G.to(device)\n",
    "  \n",
    "  T.set_epoch(epoch + 1)\n",
    "  T.change_j(j)\n",
    "\n",
    "  f = f'{URL}{DATASET}/{text}/Params/Gen_{text}{j}_{epoch}.pt'\n",
    "  \n",
    "  if torch.cuda.is_available():\n",
    "    G.load_state_dict(torch.load(f))\n",
    "  else:\n",
    "    G.load_state_dict(torch.load(f, map_location=torch.device('cpu')))\n",
    "\n",
    "  f = f'{URL}{DATASET}/{text}/Params/Disc_{text}{j}_{epoch}.pt'\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "    D.load_state_dict(torch.load(f))\n",
    "  else:\n",
    "    D.load_state_dict(torch.load(f, map_location=torch.device('cpu')))\n",
    "      \n",
    "  generate_images(G)\n",
    "\n",
    "  return G, D, T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nc8e0ZDM0YZK"
   },
   "source": [
    "# Helper Functions: Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3urpsGj5N18"
   },
   "outputs": [],
   "source": [
    "def save_classifier(C, text, j, i): \n",
    "  f = f'{URL}{DATASET}/Classifier/Classifier_{text}{j}_{i}.pt'\n",
    "  torch.save(C.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEQFwrvZ5Pna"
   },
   "outputs": [],
   "source": [
    "def load_classifier(text, j, i):\n",
    "  C = Classifier(NUM_FEATURES)\n",
    "  f = f'{URL}{DATASET}/Classifier/Classifier_{text}{j}_{i}.pt'\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "      C.load_state_dict(torch.load(f))\n",
    "  else:\n",
    "      C.load_state_dict(torch.load(f, map_location=torch.device('cpu')))\n",
    "\n",
    "  C.to(device)\n",
    "\n",
    "  return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0DnaDJFPaxu"
   },
   "outputs": [],
   "source": [
    "def print_results(d, verbose):\n",
    "\n",
    "  if verbose:\n",
    "    print(f'True positive count for {TEXT1}: {d[\"s1_tp\"]}')\n",
    "    print(f'False positive count for {TEXT1}: {d[\"s1_fp\"]}')\n",
    "    print(f'True negative count for {TEXT1}: {d[\"s1_tn\"]}')\n",
    "    print(f'False negative count for {TEXT1}: {d[\"s1_fn\"]} \\n')\n",
    "    print(f'True positive count for {TEXT0}: {d[\"s0_tp\"]}')\n",
    "    print(f'False positive count for {TEXT0}: {d[\"s0_fp\"]}')\n",
    "    print(f'True negative count for {TEXT0}: {d[\"s0_tn\"]}')\n",
    "    print(f'False negative count for {TEXT0}: {d[\"s0_fn\"]} \\n')\n",
    "  else:\n",
    "    print(d[\"s1_tp\"])\n",
    "    print(d[\"s1_fp\"])\n",
    "    print(d[\"s1_tn\"])\n",
    "    print(d[\"s1_fn\"])\n",
    "    print(d[\"s0_tp\"])\n",
    "    print(d[\"s0_fp\"])\n",
    "    print(d[\"s0_tn\"])\n",
    "    print(d[\"s0_fn\"])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEf2p3O3SVUf"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(d, verbose):\n",
    "  s1_acc = (d['s1_tp'] + d['s1_tn']) / (d['s1_tp'] + d['s1_fp'] + d['s1_tn'] + d['s1_fn'])\n",
    "  s0_acc = (d['s0_tp'] + d['s0_tn']) / (d['s0_tp'] + d['s0_fp'] + d['s0_tn'] + d['s0_fn'])\n",
    "\n",
    "  acc = (d['s1_tp'] + d['s1_tn'] + d['s0_tp'] + d['s0_tn']) / (d['s1_tp'] + d['s1_fp'] + d['s1_tn'] + d['s1_fn'] + d['s0_tp'] + d['s0_fp'] + d['s0_tn'] + d['s0_fn'])\n",
    "\n",
    "  if verbose:\n",
    "    print(f'Classification accuracy for {TEXT1} subgroup is {round(s1_acc, 3)}')\n",
    "    print(f'Classification accuracy for {TEXT0} subgroup is {round(s0_acc, 3)}')\n",
    "    print(f'Difference in classification accuracy is {round(s1_acc - s0_acc, 3)}')\n",
    "    print(f'Overall classification accuracy is {round(acc, 3)} \\n')\n",
    "  else:\n",
    "    print(round(s1_acc, 3))\n",
    "    print(round(s0_acc, 3))\n",
    "    print(round(s1_acc - s0_acc, 3))\n",
    "    print(round(acc, 3))\n",
    "\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mw82tU-fSVhs"
   },
   "outputs": [],
   "source": [
    "def get_dp(d, verbose):\n",
    "  # conditional classification accuracy\n",
    "  dp_s1 = (d['s1_tp'] + d['s1_fp']) / (d['s1_tp'] + d['s1_fp'] + d['s1_tn'] + d['s1_fn'])\n",
    "  dp_s0 = (d['s0_tp'] + d['s0_fp']) / (d['s0_tp'] + d['s0_fp'] + d['s0_tn'] + d['s0_fn'])\n",
    "\n",
    "  dp = dp_s1 - dp_s0\n",
    "  \n",
    "  if verbose:\n",
    "    print(f'Conditional classification accuracy for {TEXT1} subgroup is {round(dp_s1, 3)}')\n",
    "    print(f'Conditional classification accuracy for {TEXT0} subgroup is {round(dp_s0, 3)}')\n",
    "    print(f'Demographic parity difference is {round(dp, 3)} \\n')\n",
    "  else:\n",
    "    print(round(dp_s1, 3))\n",
    "    print(round(dp_s0, 3))\n",
    "    print(round(dp, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iynbWO4BSVto"
   },
   "outputs": [],
   "source": [
    "def get_eo(d, verbose):\n",
    "  # false positive rates\n",
    "  eo_s1 = d['s1_tp'] / (d['s1_tp'] + d['s1_fn'])\n",
    "  eo_s0 = d['s0_tp'] / (d['s0_tp'] + d['s0_fn'])\n",
    "\n",
    "  eo = eo_s1 - eo_s0\n",
    "\n",
    "  if verbose:\n",
    "    print(f'True positive rate for {TEXT1} subgroup is {round(eo_s1, 3)}')\n",
    "    print(f'True positive rate for {TEXT0} subgroup is {round(eo_s0, 3)}')\n",
    "    print(f'Equality of opportunity difference is {round(eo, 3)} \\n')\n",
    "  else:\n",
    "    print(round(eo_s1, 3))\n",
    "    print(round(eo_s0, 3))\n",
    "    print(round(eo, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOhultSL0NrW"
   },
   "source": [
    "# Discriminator, Generator, GAN Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Xm12_QJRlfv"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, disc_features):\n",
    "    super().__init__()\n",
    "\n",
    "    # build model\n",
    "    self.model = nn.Sequential(\n",
    "      nn.Conv2d(3, disc_features, kernel_size=4, stride=2, padding=1),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      \n",
    "      self.block(disc_features, disc_features * 2, 4, 2, 1),\n",
    "      self.block(disc_features * 2, disc_features * 4, 4, 2, 1),\n",
    "      self.block(disc_features * 4, disc_features * 8, 4, 2, 1))\n",
    "\n",
    "    self.model_source = nn.Sequential(\n",
    "      nn.Linear(GAN_BATCH_SIZE * disc_features * 128, GAN_BATCH_SIZE),\n",
    "      nn.Sigmoid())\n",
    "    \n",
    "    self.model_outcome = nn.Sequential(\n",
    "      nn.Linear(GAN_BATCH_SIZE * disc_features * 128, GAN_BATCH_SIZE),\n",
    "      nn.Sigmoid())\n",
    "  \n",
    "  def block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "    return nn.Sequential(\n",
    "      nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      nn.Dropout(0.5))\n",
    "\n",
    "  # run model\n",
    "  def forward(self, inputs):\n",
    "    t = self.model(inputs).flatten()\n",
    "    return self.model_source(t), self.model_outcome(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJWhQXCZsC9h"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self, noise_size, gen_features):\n",
    "    super().__init__()\n",
    "\n",
    "    # build model\n",
    "    self.model = nn.Sequential(\n",
    "      self.block(noise_size, gen_features * 16, 4, 1, 0),\n",
    "      self.block(gen_features * 16, gen_features * 8, 4, 2, 1),\n",
    "      self.block(gen_features * 8, gen_features * 4, 4, 2, 1),\n",
    "      self.block(gen_features * 4, gen_features * 2, 4, 2, 1),\n",
    "      nn.ConvTranspose2d(gen_features * 2, 3, 4, 2, 1),\n",
    "      nn.Tanh())\n",
    "    \n",
    "  def block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "    return nn.Sequential(\n",
    "      nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.ReLU())\n",
    "\n",
    "  # run model\n",
    "  def forward(self, inputs):\n",
    "    return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSiuM_p68qHC"
   },
   "outputs": [],
   "source": [
    "def train_gan(G, D, T, train_loader, epochs, text, save):\n",
    "\n",
    "  loss_function = nn.BCELoss()\n",
    "\n",
    "  optim_D = torch.optim.Adam(D.parameters(), lr = D_LEARNING_RATE, betas=(0.5, 0.999))\n",
    "  optim_G = torch.optim.Adam(G.parameters(), lr = G_LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "  end_epoch = T.epoch + epochs - 1\n",
    "\n",
    "  for i in range(epochs):\n",
    "\n",
    "    if URL == '':\n",
    "      loop = train_loader\n",
    "      print(f'Epoch is {T.epoch}')\n",
    "    else:\n",
    "      loop = tqdm(train_loader)\n",
    "      loop.set_description(f'Epoch {T.epoch}/{end_epoch}')\n",
    "    \n",
    "    for batch in loop:\n",
    "\n",
    "      X, y, s = batch\n",
    "      y = y.view(GAN_BATCH_SIZE).to(device)\n",
    "        \n",
    "      # discard non-full batches\n",
    "      if len(X) == GAN_BATCH_SIZE:\n",
    "\n",
    "          # train D on a batch of reals\n",
    "          DR_source, DR_outcome = D.forward(X.to(device))\n",
    "          T.track('Real', DR_source)\n",
    "          DR_loss_source = loss_function(DR_source, torch.ones_like(DR_source))       \n",
    "          DR_loss_outcome = loss_function(DR_outcome, y)\n",
    "        \n",
    "          # train D on a batch of fakes\n",
    "          gen_image = G.forward(torch.randn(GAN_BATCH_SIZE, NOISE, 1, 1).to(device))\n",
    "          targets_outcome = random_classes().to(device)\n",
    "\n",
    "          DF_source, DF_outcome = D.forward(gen_image.detach())\n",
    "          T.track('Fake', DF_source)\n",
    "          DF_loss_source = loss_function(DF_source, torch.zeros_like(DF_source))          \n",
    "          DF_loss_outcome = loss_function(DF_outcome, targets_outcome)\n",
    "                                         \n",
    "          # get total loss for D\n",
    "          loss_DR = (DR_loss_source + DR_loss_outcome) / 2\n",
    "          loss_DF = (DF_loss_source + DF_loss_outcome) / 2\n",
    "          loss_D = (loss_DR + loss_DF) / 2\n",
    "          T.add_d_loss(loss_D.item())\n",
    "\n",
    "          D.zero_grad()\n",
    "          loss_D.backward()\n",
    "          optim_D.step()\n",
    "\n",
    "          # train G using D loss\n",
    "          # don't use detach here so gradient flows\n",
    "          gen_image = G.forward(torch.randn(GAN_BATCH_SIZE, NOISE, 1, 1).to(device))\n",
    "          targets_outcome = random_classes().to(device)\n",
    "        \n",
    "          G_source, G_outcome = D.forward(gen_image)\n",
    "          G_loss_source = loss_function(G_source, torch.ones_like(G_source))\n",
    "            \n",
    "          if text == 'EO':\n",
    "            G_outcome, targets_outcome = eo_loss(G_outcome, targets_outcome)\n",
    "          elif text == 'CF':\n",
    "            G_outcome, targets_outcome = cf_loss(G_outcome, targets_outcome)\n",
    "\n",
    "          G_loss_outcome = loss_function(G_outcome, targets_outcome)\n",
    "\n",
    "          loss_G = (G_loss_source + G_loss_outcome) / 2\n",
    "          T.add_g_loss(loss_G.item())\n",
    "\n",
    "          G.zero_grad()\n",
    "          loss_G.backward()\n",
    "          optim_G.step()\n",
    "            \n",
    "    if save != 0 and T.epoch % save == 0:\n",
    "      save_gan(G, D, text, T.j, T.epoch)\n",
    "\n",
    "    T.add_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxWlOLWVLpeg"
   },
   "outputs": [],
   "source": [
    "def cf_loss(outputs, targets):\n",
    "\n",
    "    l = []\n",
    "    \n",
    "    for i in range(GAN_BATCH_SIZE):\n",
    "        if targets[i] == 0.0:\n",
    "            l.append(i)\n",
    "        else:\n",
    "            r = random.random()\n",
    "            if r >= ALPHA:\n",
    "                l.append(i)\n",
    "            \n",
    "    index = torch.tensor(l, dtype=torch.int).to(device)\n",
    "    \n",
    "    fair_outputs = outputs.index_select(0, index)\n",
    "    fair_targets = targets.index_select(0, index)\n",
    "\n",
    "    return fair_outputs, fair_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eo_loss(outputs, targets):\n",
    "\n",
    "    l = []\n",
    "    \n",
    "    for i in range(GAN_BATCH_SIZE):\n",
    "        if targets[i] == 0.0:\n",
    "            l.append(i)\n",
    "            \n",
    "    index = torch.tensor(l, dtype=torch.int).to(device)\n",
    "    \n",
    "    fair_outputs = outputs.index_select(0, index)\n",
    "    fair_targets = targets.index_select(0, index)\n",
    "\n",
    "    return fair_outputs, fair_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVvsREOuVLi2"
   },
   "source": [
    "# Classifier, Train and Test Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOkZAc3Gau0x"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "  def __init__(self, c_features):\n",
    "    super(Classifier, self).__init__()\n",
    "\n",
    "    # build model\n",
    "    self.model = nn.Sequential(\n",
    "      nn.Conv2d(3, c_features, kernel_size=4, stride=2, padding=1),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      \n",
    "      self.block(c_features, c_features * 2, 4, 2, 1),\n",
    "      self.block(c_features * 2, c_features * 4, 4, 2, 1),\n",
    "      self.block(c_features * 4, c_features * 8, 4, 2, 1))\n",
    "    \n",
    "    self.model2 = nn.Sequential(\n",
    "      nn.Linear(CLASSIFIER_BATCH_SIZE * c_features * 128, CLASSIFIER_BATCH_SIZE),\n",
    "      nn.Sigmoid())\n",
    "  \n",
    "  def block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "    return nn.Sequential(\n",
    "      nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      nn.Dropout(0.5)\n",
    "      )\n",
    "      \n",
    "  def forward(self, inputs):\n",
    "    t = self.model(inputs)\n",
    "    return self.model2(t.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8Dc-7Uty-8Z"
   },
   "outputs": [],
   "source": [
    "def train_classifier(C, CT, train_loader, validation_loader, text, fair):\n",
    "  epoch = 0\n",
    "  count = 0\n",
    "  best_epoch = 0\n",
    "  best_acc = 0\n",
    "\n",
    "  loss_function = nn.BCELoss()\n",
    "  optimiser = torch.optim.Adam(C.parameters(), lr=CLASSIFIER_LEARNING_RATE)\n",
    "  \n",
    "  C.train()\n",
    "\n",
    "  while count < 5:\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "    if URL == '':\n",
    "      loop = train_loader\n",
    "    else:\n",
    "      loop = tqdm(train_loader)\n",
    "      loop.set_description(f'Epoch {epoch}')\n",
    "\n",
    "    for batch in loop:\n",
    "\n",
    "      if fair == True:\n",
    "        X, y = batch\n",
    "      else:\n",
    "        X, y, _ = batch\n",
    "\n",
    "      # discard non-full batches\n",
    "      if len(X) == CLASSIFIER_BATCH_SIZE:\n",
    "\n",
    "        # run model\n",
    "        outputs = C.forward(X.detach().to(device))\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_function(outputs, y.view(CLASSIFIER_BATCH_SIZE).detach().to(device))\n",
    "        CT.add_loss(loss.item())\n",
    "\n",
    "        # zero gradients, backward pass, update weights\n",
    "        C.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "  \n",
    "    if epoch % 3 == 0:\n",
    "\n",
    "      train_acc = test_acc(C, train_loader, TRAIN, fair)\n",
    "      CT.add_train_acc(train_acc)\n",
    "\n",
    "      val_acc = test_acc(C, validation_loader, VAL, False)\n",
    "      CT.add_val_acc(val_acc)\n",
    "      \n",
    "      if val_acc > best_acc:\n",
    "        count = 0\n",
    "        best_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        save_classifier(C, text, CT.j, best_epoch)\n",
    "      else:\n",
    "        count += 1\n",
    "\n",
    "  return best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(C, loader, n, fair):\n",
    "\n",
    "  C.eval()\n",
    "  pos = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch in loader:\n",
    "      if fair == True:\n",
    "        X, y = batch\n",
    "      else:\n",
    "        X, y, _ = batch\n",
    "      k = CLASSIFIER_BATCH_SIZE\n",
    "\n",
    "      # pad non-full batches\n",
    "      if len(X) != CLASSIFIER_BATCH_SIZE:\n",
    "        k = len(X)\n",
    "        X_mod = torch.ones(CLASSIFIER_BATCH_SIZE, 3, DIM, DIM)\n",
    "        X_mod[:k] = X\n",
    "      else:\n",
    "        X_mod = X\n",
    "  \n",
    "      t = C.forward(X_mod.to(device))\n",
    "\n",
    "      for i in range(k):\n",
    "        if y[i].item() == 1.0 and t[i].item() >= 0.5:\n",
    "          pos += 1\n",
    "        elif y[i].item() == 0.0 and t[i].item() < 0.5:\n",
    "          pos += 1\n",
    "\n",
    "  C.train()\n",
    "\n",
    "  return pos / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPse_xiLPZ6u"
   },
   "outputs": [],
   "source": [
    "def test_classifier(C, loader):\n",
    "\n",
    "  C.eval()\n",
    "  \n",
    "  d = {\n",
    "    's1_tp': 0,\n",
    "    's1_fp': 0,\n",
    "    's1_tn': 0,\n",
    "    's1_fn': 0,\n",
    "    's0_tp': 0,\n",
    "    's0_fp': 0,\n",
    "    's0_tn': 0,\n",
    "    's0_fn': 0\n",
    "  }\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch in loader:\n",
    "      X, y, s = batch\n",
    "      k = CLASSIFIER_BATCH_SIZE\n",
    "\n",
    "      # pad non-full batches\n",
    "      if len(X) != CLASSIFIER_BATCH_SIZE:\n",
    "        k = len(X)\n",
    "        X_mod = torch.ones(CLASSIFIER_BATCH_SIZE, 3, DIM, DIM)\n",
    "        X_mod[:k] = X\n",
    "      else:\n",
    "        X_mod = X\n",
    "  \n",
    "      t = C.forward(X_mod.to(device))\n",
    "\n",
    "      for i in range(k):\n",
    "        if s[i].item() == 1.0:\n",
    "          if y[i].item() == 1.0:\n",
    "            if t[i].item() >= 0.5:\n",
    "              d['s1_tp'] += 1\n",
    "            else:\n",
    "              d['s1_fn'] += 1\n",
    "          else:\n",
    "            if t[i].item() >= 0.5:\n",
    "              d['s1_fp'] += 1\n",
    "            else:\n",
    "              d['s1_tn'] += 1\n",
    "        else:\n",
    "          if y[i].item() == 1.0:\n",
    "            if t[i].item() >= 0.5:\n",
    "              d['s0_tp'] += 1\n",
    "            else:\n",
    "              d['s0_fn'] += 1\n",
    "          else:\n",
    "            if t[i].item() >= 0.5:\n",
    "              d['s0_fp'] += 1\n",
    "            else:\n",
    "              d['s0_tn'] += 1\n",
    "\n",
    "  C.train()\n",
    "\n",
    "  return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_IwqykBP5Ee"
   },
   "source": [
    "# Train Classifier on Real Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwmLJLywQ7zo"
   },
   "outputs": [],
   "source": [
    "f1 = f'{URL}{DATASET}/Images/SCUTData.csv'\n",
    "f2 = f'{URL}{DATASET}/Images/'\n",
    "\n",
    "SCUTData = MyDataset(f1, f2, DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "soHLiaddeueK"
   },
   "outputs": [],
   "source": [
    "check_skew(SCUTData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtLbZvHHtA9W"
   },
   "outputs": [],
   "source": [
    "train_loader, validation_loader, test_loader = load_real_data(SCUTData, CLASSIFIER_BATCH_SIZE, (7/11), (2/11), (2/11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Et_SYq5atmMB"
   },
   "outputs": [],
   "source": [
    "save_splits(f'Real/Splits/{SPLIT}', train_loader, validation_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzhEAMlcb7tP"
   },
   "outputs": [],
   "source": [
    "train_loader = read_split(f'Real/Splits/{SPLIT}', CLASSIFIER_BATCH_SIZE, 'Train', load=True, fair=False)\n",
    "validation_loader = read_split(f'Real/Splits/{SPLIT}', CLASSIFIER_BATCH_SIZE, 'Validation', load=True, fair=False)\n",
    "test_loader = read_split(f'Real/Splits/{SPLIT}', CLASSIFIER_BATCH_SIZE, 'Test', load=True, fair=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Am1F5E2UPaxu"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    C = Classifier(NUM_FEATURES)\n",
    "    CT = C_Tracker()\n",
    "\n",
    "    C.to(device)\n",
    "\n",
    "    best_epoch = train_classifier(C, CT, train_loader, validation_loader, 'Real', fair=False)\n",
    "\n",
    "    C = load_classifier('Real', CT.j, best_epoch)\n",
    "\n",
    "    print(CT.j)\n",
    "    print(best_epoch)\n",
    "    d = test_classifier(C, test_loader)\n",
    "    print_results(d, False)\n",
    "    get_accuracy(d, False)\n",
    "    get_dp(d, False)\n",
    "    get_eo(d, False)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgF2F_GmxM7W"
   },
   "outputs": [],
   "source": [
    "plot_classifier(CT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYgGgjD9QT2j"
   },
   "source": [
    "# Train Classifier on Generated Train Set (Demographic Parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxmKN0se8ehm"
   },
   "source": [
    "**Train Demographic Parity GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNalhwM-Paxw"
   },
   "outputs": [],
   "source": [
    "D_DP = Discriminator(NUM_FEATURES)\n",
    "G_DP = Generator(NOISE, NUM_FEATURES)\n",
    "T_DP = Tracker()\n",
    "\n",
    "G_DP.to(device)\n",
    "D_DP.to(device)\n",
    "\n",
    "initialise_weights(D_DP)\n",
    "initialise_weights(G_DP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOO2wpqF_FL4"
   },
   "outputs": [],
   "source": [
    "train_loader = read_split(f'Real/Splits/{SPLIT}', GAN_BATCH_SIZE, 'Train', load=True, fair=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-O6shvohAdVw"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_gan(G_DP, D_DP, T_DP, train_loader, 400, 'DP', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gan(G_DP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BW_jZVqx63q5"
   },
   "outputs": [],
   "source": [
    "generate_images(G_DP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uyY1kwq8aGX"
   },
   "source": [
    "**Load in GAN checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Tagxh4A6pZl"
   },
   "outputs": [],
   "source": [
    "G_DP, D_DP, T_DP = load_gan('DP', 999, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IX9t8Yu-8T9u"
   },
   "source": [
    "**Generate data from trained GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKNUAP-CRUzJ"
   },
   "outputs": [],
   "source": [
    "generate_dataset(G_DP, D_DP, 'DP', f'Images/{SPLIT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLd7F_Z2794h"
   },
   "outputs": [],
   "source": [
    "X_DP, y_DP = read_tensors('DP', f'Images/{SPLIT}', TRAIN, fair=True)\n",
    "dp_data = FairDataset(X_DP, y_DP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTXWPaLmzrBM"
   },
   "source": [
    "**Save and load splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjHTGjn8cB_M"
   },
   "outputs": [],
   "source": [
    "dp_train_loader = DataLoader(dp_data, CLASSIFIER_BATCH_SIZE, shuffle=True)\n",
    "validation_loader = read_split(f'Real/Splits/{SPLIT}', CLASSIFIER_BATCH_SIZE, 'Validation', load=True, fair=False)\n",
    "test_loader = read_split(f'Real/Splits/{SPLIT}', CLASSIFIER_BATCH_SIZE, 'Test', load=True, fair=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LTeXI1C0kEp"
   },
   "source": [
    "**Test classifier using generated dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yj3remPeQ_Vc"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    C_DP = Classifier(NUM_FEATURES)\n",
    "    CT_DP = C_Tracker()\n",
    "\n",
    "    C_DP.to(device)\n",
    "\n",
    "    best_epoch = train_classifier(C_DP, CT_DP, dp_train_loader, validation_loader, 'DP', fair=True)\n",
    "\n",
    "    C_DP = load_classifier('DP', CT_DP.j, best_epoch)\n",
    "\n",
    "    print(CT_DP.j)\n",
    "    print(best_epoch)\n",
    "    d = test_classifier(C_DP, test_loader)\n",
    "    print_results(d, False)\n",
    "    get_accuracy(d, False)\n",
    "    get_dp(d, False)\n",
    "    get_eo(d, False)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SPK-zigh2jR4"
   },
   "outputs": [],
   "source": [
    "plot_classifier(CT_DP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-wmdl0QQYiI"
   },
   "source": [
    "# Train Classifier on Generated Train Set (Equality of Opportunity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H75r7ydKAn-S"
   },
   "source": [
    "**Train Equality of Opportunity GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4ePcuh_SRAI"
   },
   "outputs": [],
   "source": [
    "D_EO = Discriminator(NUM_FEATURES)\n",
    "G_EO = Generator(NOISE, NUM_FEATURES)\n",
    "T_EO = Tracker()\n",
    "\n",
    "G_EO.to(device)\n",
    "D_EO.to(device)\n",
    "\n",
    "initialise_weights(D_EO)\n",
    "initialise_weights(G_EO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ri30rYrKIGyF"
   },
   "outputs": [],
   "source": [
    "train_loader = read_split(f'Real/Splits/{SPLIT}', GAN_BATCH_SIZE, 'Train', load=True, fair=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2F1f1aDBSZnA"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_gan(G_EO, D_EO, T_EO, train_loader, 400, 'EO', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJDzUHYQ5XOC"
   },
   "outputs": [],
   "source": [
    "plot_gan(T_EO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vF1P9gzgcnh8"
   },
   "outputs": [],
   "source": [
    "generate_images(G_EO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvyAME3NBKZC"
   },
   "source": [
    "**Load in GAN checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDv4d30nBUe8"
   },
   "outputs": [],
   "source": [
    "G_EO, D_EO, T_EO = load_gan('EO', 999, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTzQeEh3Bqfo"
   },
   "source": [
    "**Generate data from trained GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlsGNzNLBwPH"
   },
   "outputs": [],
   "source": [
    "generate_dataset(G_EO, D_EO, 'EO', f'Images/{SPLIT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ka1FRxU7B44a"
   },
   "outputs": [],
   "source": [
    "X_EO, y_EO = read_tensors('EO', f'Images/{SPLIT}', TRAIN, fair=True)\n",
    "eo_data = FairDataset(X_EO, y_EO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ya6v2yyTzX0a"
   },
   "source": [
    "**Save and load splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFjUz_I4cNfU"
   },
   "outputs": [],
   "source": [
    "eo_train_loader = DataLoader(eo_data, CLASSIFIER_BATCH_SIZE, shuffle=True)\n",
    "validation_loader = read_split(f'Real/Splits/{SPLIT}', CLASSIFIER_BATCH_SIZE, 'Validation', load=True, fair=False)\n",
    "test_loader = read_split(f'Real/Splits/{SPLIT}', CLASSIFIER_BATCH_SIZE, 'Test', load=True, fair=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkXbbjmM1u2j"
   },
   "source": [
    "**Test classifier using generated dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-7v2hqNTDU1"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    C_EO = Classifier(NUM_FEATURES)\n",
    "    CT_EO = C_Tracker()\n",
    "\n",
    "    C_EO.to(device)\n",
    "\n",
    "    best_epoch = train_classifier(C_EO, CT_EO, eo_train_loader, validation_loader, 'EO', True)\n",
    "\n",
    "    C_DP = load_classifier('EO', CT_EO.j, best_epoch)\n",
    "\n",
    "    print(CT_EO.j)\n",
    "    print(best_epoch)\n",
    "    d = test_classifier(C_EO, test_loader)\n",
    "    print_results(d, False)\n",
    "    get_accuracy(d, False)\n",
    "    get_dp(d, False)\n",
    "    get_eo(d, False)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtOoBAmc2t5N"
   },
   "outputs": [],
   "source": [
    "plot_classifier(CT_EO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcCiPfxaQc4f"
   },
   "source": [
    "# Train Classifier on Generated Train Set (Combined Fairness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5nymD5WC7Ga"
   },
   "source": [
    "**Train Combined Fairness (DP and EO) GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDEkOyVaTVAC"
   },
   "outputs": [],
   "source": [
    "D_CF = Discriminator(NUM_FEATURES)\n",
    "G_CF = Generator(NOISE, NUM_FEATURES)\n",
    "T_CF = Tracker()\n",
    "\n",
    "G_CF.to(device)\n",
    "D_CF.to(device)\n",
    "\n",
    "initialise_weights(D_CF)\n",
    "initialise_weights(G_CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMtFff0B-dcV"
   },
   "outputs": [],
   "source": [
    "train_loader = read_split(f'Real/Splits/{SPLIT}', GAN_BATCH_SIZE, 'Train', load=True, fair=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bM-4-2-0TVeI"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ALPHA = 0.25\n",
    "train_gan(G_CF, D_CF, T_CF, train_loader, 80, 'CF', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4L7ACyGP5crh"
   },
   "outputs": [],
   "source": [
    "plot_gan(T_CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OceprCD5haR"
   },
   "outputs": [],
   "source": [
    "generate_images(G_CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_L4stHUU5rPr"
   },
   "source": [
    "**Load in GAN checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zd7zYwTN5w42"
   },
   "outputs": [],
   "source": [
    "G_CF, D_CF, T_CF = load_gan('CF', 999, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ztix9w_-DAS3"
   },
   "source": [
    "**Generate data from trained GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PWDVVw4DFKS"
   },
   "outputs": [],
   "source": [
    "generate_dataset(G_CF, D_CF, 'CF', f'Images/{SPLIT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNh0gdYaT8cv"
   },
   "outputs": [],
   "source": [
    "X_CF, y_CF = read_tensors('CF', f'Images/{SPLIT}', TRAIN, fair=True)\n",
    "cf_data = FairDataset(X_CF, y_CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SWTWs6bziBk"
   },
   "source": [
    "**Save and load splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZ09ByRtcYKC"
   },
   "outputs": [],
   "source": [
    "cf_train_loader = DataLoader(cf_data, CLASSIFIER_BATCH_SIZE, shuffle=True)\n",
    "validation_loader = read_split(f'Real/Splits/{SPLIT}', CLASSIFIER_BATCH_SIZE, 'Validation', load=True, fair=False)\n",
    "test_loader = read_split(f'Real/Splits/{SPLIT}', CLASSIFIER_BATCH_SIZE, 'Test', load=True, fair=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKFtHuH43kSj"
   },
   "source": [
    "**Test classifier using generated dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yvd6UwN8T9d9"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    C_CF = Classifier(NUM_FEATURES)\n",
    "    CT_CF = C_Tracker()\n",
    "\n",
    "    C_CF.to(device)\n",
    "\n",
    "    best_epoch = train_classifier(C_CF, CT_CF, cf_train_loader, validation_loader, 'CF', fair=True)\n",
    "\n",
    "    C_CF = load_classifier('CF', CT_CF.j, best_epoch)\n",
    "\n",
    "    print(CT_CF.j)\n",
    "    print(best_epoch)\n",
    "    d = test_classifier(C_CF, test_loader)\n",
    "    print_results(d, False)\n",
    "    get_accuracy(d, False)\n",
    "    get_dp(d, False)\n",
    "    get_eo(d, False)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6qefn2Y339t"
   },
   "outputs": [],
   "source": [
    "plot_classifier(CT_CF)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SCUT_Dataset_OG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
